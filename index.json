[{"content":"","date":"29 March 2025","externalUrl":null,"permalink":"/tags/buaa/","section":"标签","summary":"","title":"BUAA","type":"tags"},{"content":" 量子电梯、影子电梯、猴子电梯、开子电梯……\nJUnit、投喂包和编译打包相关 # JUnit # OO 第二单元电梯，为了方便我们进行输入输出，课程组提供了 dataInput 程序对我们编译好的 jar 包进行管道输入，并提供一个 elevatorX.jar 作为我们代码的依赖。然而在使用过程中有诸多不便：\n每次测试程序，都需要打包一遍，再从 out/ 文件夹下拖出来 Windows 下 powershell 还运行不了（奇奇怪怪，是为什么呢？） 即便好心的睿睿准备了一个更好用的数据投喂机，但它需要作为 main 方法来使用，而且还不能上传到公测提交中（当然会查重）。\n这时候，我们可以使用曾经在 oop 中接触到的 JUnit 方法，将 testMain/dataInput 等定时向我们的程序提供输入的方法编写为一个测试单元，运用测试单元就可以不用担心两个 main 方法的问题啦。\n因为 JUnit 方法虽然可以上传提交，但是仍然会经过查重，这里不提供详细代码。所以下面仅提供一个我的操作流程，供大家参考。\n软盘+蟒蛇图标 # 看到 dataInput 那个经典图标，我就知道这是 PyInstaller 打包的 Python 程序，于是从网上搜索了如何将它反编译出源码，并顺利得到了 dataInput 的源码。嗯，这么点源码打包成 5MB 的程序，太有 PyInstaller 那味了。\nAI 机器，小子！ # 其实不管是 dataInput 的源码，还是 TestMain 的源码，都有被查重的风险，所以最简单的办法当然是拿着这些源码去找 AI，让它根据源码为我们写一个 MainClass.main()（或者 Main.main() 之类）的 JUnit 方法就好了。不过 AI 生成也不一定完全能够保证不被查重（\n然后照着 oop 的方法设置 JUnit 就好了。\n输入输出重定向 # 我发现测试方法的运行配置里没有“重定向输入”的选择，只有“将控制台输出保存到文件”的选择。也就是说我们得在 JUnit 方法里实现输入输出重定向。\n我们可以使用 java.nio.file 下的 Paths、Path、Files 等类来实现重定向。后面带 s 的俩类提供了许多静态方法。\nPath testFilePath = Paths.get(System.getProperty(\u0026#34;user.dir\u0026#34;), \u0026#34;stdin.txt\u0026#34;); Path outputFilePath = Paths.get(System.getProperty(\u0026#34;user.dir\u0026#34;), \u0026#34;usrout.txt\u0026#34;); List\u0026lt;String\u0026gt; lines = Files.readAllLines(testFilePath); PrintStream outputStream = new PrintStream(Files.newOutputStream(outputFilePath.toFile().toPath())); System.setOut(outputStream); 这里我们将标准输出重定向到了 usrout.txt 文件，这个文件在用户当前工作目录下，也就是我们的项目的根目录下。\nstdin.txt 就是带时间戳的输入，也放在同一目录下，使用 Paths.get() 和 Files.readAllLines() 读取到 List\u0026lt;String\u0026gt; 中。\n清理线程 # 实际使用 JUnit 方法时遇到了一些问题：\nMainClass.main() 方法一般都是创建线程、启动线程，然后就不管这些线程的死活了。 JUnit 方法执行完成之后，IDEA 就直接把整个程序结束了。 也就是说，当 JUnit 方法把输入定时交给程序完成之后，程序就结束了，电梯线程以及其他线程就会被终止。\n即便我们在 JUnit 方法里创建 main 方法的线程（比如叫 mainThread），然后在最后使用 mainThread.join() 等待线程结束。\n但我们等待的只是 mainThread 这一线程的结束：当 main 方法运行完成之后，它就结束了。我们并不能确定 main 方法中创建的其他线程的状态。\n所以解决办法有两个：\n在 main 方法中创建并收集线程，并在最后使用 thread.join() 方法等待所有线程结束。 在 JUnit 方法中一开始记录程序运行中的所有线程；在方法结束之前，再次记录程序运行中的所有线程，减去前面的进程，就可以得到 main 方法中创建的进程了。之后再等待这些线程结束就好了。 对于第二个方法，部分代码如下：\nSet\u0026lt;Thread\u0026gt; initThreads = new HashSet\u0026lt;\u0026gt;(Thread.getAllStackTraces().keySet()); // ... after start main thread Set\u0026lt;Thread\u0026gt; curThreads = new HashSet\u0026lt;\u0026gt;(Thread.getAllStackTraces().keySet()); curThreads.removeAll(initThreads); Set\u0026lt;Thread\u0026gt; userThreads = new HashSet\u0026lt;\u0026gt;(); for (Thread t : curThreads) { if (t.isAlive() \u0026amp;\u0026amp; !t.isDaemon()) { userThreads.add(t); } } 这里需要排除一些 Daemon 守护线程，一般作垃圾回收、释放内存等用途。\n编译打包 # 在编写测评机的时候，我遇到了编译打包源码的问题。\n首先是编译源码，javac 不能识别并找到官方包依赖。\n其次是打包时，jar 也不能识别并找到官方包依赖。\n查了一番资料后，我得到了以下解决方法：\njavac -d \u0026lt;project_dir\u0026gt; \u0026lt;main_class_path\u0026gt; -sourcepath \u0026lt;src_path\u0026gt; -classpath \u0026lt;path_to_elevator1_jar\u0026gt; #带依赖编译源码 jar xf \u0026lt;path_to_elevator1_jar\u0026gt; # 解压官方包 # 将解压后的文件复制到 \u0026lt;project_dir\u0026gt; 下 jar cfm \u0026lt;jar_name\u0026gt; \u0026lt;manifest_path\u0026gt; -C \u0026lt;project_dir\u0026gt; . # 将文件夹打包成 jar 其中：\n\u0026lt;project_dir\u0026gt; 就是源码的工作目录 \u0026lt;main_class_path\u0026gt; 是 main 方法所在类文件的位置 \u0026lt;src_path\u0026gt; 是指 main 方法所在类文件的所在目录，注意和 \u0026lt;project_dir\u0026gt; 的不同 \u0026lt;manifest_path\u0026gt; 是在 jar 包中固定位置与格式的一个 MANIFEST.MF 文件，可以参考其他打包好的 jar 包编写。 然后就可以得到正确的包了。\n","date":"29 March 2025","externalUrl":null,"permalink":"/posts/oounit2/","section":"归档","summary":"","title":"OO Unit2 总结","type":"posts"},{"content":"","date":"29 March 2025","externalUrl":null,"permalink":"/tags/%E5%AD%A6%E4%B9%A0/","section":"标签","summary":"","title":"学习","type":"tags"},{"content":"","date":"29 March 2025","externalUrl":null,"permalink":"/categories/%E5%BF%83%E5%BE%97/","section":"分类","summary":"","title":"心得","type":"categories"},{"content":"","date":"29 March 2025","externalUrl":null,"permalink":"/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","section":"标签","summary":"","title":"面向对象","type":"tags"},{"content":" printk(\u0026#34;Hello OS!\u0026#34;);\nThinking 1.1 objdump 参数和其他体系结构编译链接过程 # gcc 编译过程 # gcc -E src.c \u0026gt; src.i gcc -S src.i # result src.s gcc -c src.s # result src.o gcc src.o # result a.out a.out 即 assemble out 的缩写。\nflowchart LR A[src.c]--预处理--\u003eB[src.i] B--编译--\u003eC[src.s] C--汇编--\u003eD[src.o] D--链接--\u003eE[a.out] 如果我们编写一个最简单的 C 语言程序：\n// src.c void main() {} // need void explicitly, default is int 经过前三个步骤，得到了 src.o，经过反汇编 objdump -DS --section=.text src.o 得到的代码如下：\nsrc.o： 文件格式 elf32-tradbigmips Contents of section .text: 0000 27bdfff8 afbe0004 03a0f025 00000000 \u0026#39;..........%.... 0010 03c0e825 8fbe0004 27bd0008 03e00008 ...%....\u0026#39;....... 0020 00000000 00000000 00000000 00000000 ................ Disassembly of section .text: 00000000 \u0026lt;main\u0026gt;: 0: 27bdfff8 addiu sp,sp,-8 4: afbe0004 sw s8,4(sp) 8: 03a0f025 move s8,sp c: 00000000 nop 10: 03c0e825 move sp,s8 14: 8fbe0004 lw s8,4(sp) 18: 27bd0008 addiu sp,sp,8 1c: 03e00008 jr ra 20: 00000000 nop ... 实践到这里我意识到，... 是对全零段的省略，并没有省略关键信息。\n而直接使用 gcc 编译得到的可执行文件 a.out反汇编结果如下：\na.out： 文件格式 elf32-tradbigmips Contents of section .text: 4004f0 03e00025 04110001 00000000 3c1c0002 ...%........\u0026lt;... 400500 279c7b14 039fe021 0000f825 8f848018 \u0026#39;.{....!...%.... 400510 8fa50000 27a60004 2401fff8 03a1e824 ....\u0026#39;...$......$ 400520 27bdffe0 00003825 afa00010 afa20014 \u0026#39;.....8%........ 400530 afbd0018 8f998028 0320f809 00000000 .......(. ...... 400540 1000ffff 00000000 00000000 00000000 ................ 400550 3c040042 3c020042 24840014 24420014 \u0026lt;..B\u0026lt;..B$...$B.. 400560 10440007 3c1c0043 279c8010 8f998024 .D..\u0026lt;..C\u0026#39;......$ 400570 13200003 00000000 03200008 00000000 . ....... ...... 400580 03e00008 00000000 3c040042 3c020042 ........\u0026lt;..B\u0026lt;..B 400590 24840014 24450014 00a42823 00051083 $...$E....(#.... 4005a0 00052fc2 00a22821 00052843 10a00007 ../...(!..(C.... 4005b0 3c1c0043 279c8010 8f99801c 13200003 \u0026lt;..C\u0026#39;........ .. 4005c0 00000000 03200008 00000000 03e00008 ..... .......... 4005d0 00000000 27bdffe0 afb00018 3c100042 ....\u0026#39;.......\u0026lt;..B 4005e0 afbf001c 92020040 14400006 8fbf001c .......@.@...... 4005f0 0c100154 00000000 24020001 a2020040 ...T....$......@ 400600 8fbf001c 8fb00018 03e00008 27bd0020 ............\u0026#39;.. 400610 08100162 00000000 00000000 00000000 ...b............ 400620 27bdfff8 afbe0004 03a0f025 00000000 \u0026#39;..........%.... 400630 03c0e825 8fbe0004 27bd0008 03e00008 ...%....\u0026#39;....... 400640 00000000 00000000 00000000 00000000 ................ Disassembly of section .text: # 篇幅限制，省略后文 经过对比可以发现，一个默认的可执行文件除了包含编写的代码以外，还添加了：\n程序入口点 __start 异常处理和程序终止 hlt 线程局部存储支持 全局对象构造和析构的支持 此外，前一个目标文件的机器码地址从 0x0 开始，这是一种相对地址；后一个可执行文件的机器码地址从 0x4004f0 开始，这已经是程序执行时其虚拟地址空间中的绝对地址了。至于为什么不是从 0x0040_0000 开始，还有 1264 字节的偏移量，大概是在 __start 之前还有 elf 文件头等各种信息需要存储。\n所以一个 C 语言程序运行的真正入口不是 main 函数，而是 __start。\n当程序运行时，操作系统加载这个可执行文件，从 __start 入口点开始执行，初始化运行环境，然后调用 main 函数，最后在 main 返回后清理资源并退出。\nobjdump 参数解析 # objdump -s：默认显示所有非空节的完整内容。每行表现形式为起始地址+机器码+ASCII字符表示。 objdump -S：尽可能反汇编出源代码。建议配合编译时 -g 参数使用。 objdump -d：反汇编特定内容，比如 main 函数。 objdump -D：反汇编所有的节。 Thinking 1.2 readelf 程序的问题 # 执行结果 # 0:0x0 1:0x80020000 2:0x80022090 3:0x800220a8 4:0x800220c0 5:0x0 6:0x0 7:0x0 8:0x0 9:0x0 10:0x0 11:0x0 12:0x0 13:0x0 14:0x0 15:0x0 16:0x0 17:0x0 18:0x0 上述执行结果代表内核 ELF 文件的各节头的地址信息。结合系统内置的 readelf程序的输出结果，可知上述结果准确无误。继续观察内置程序的输出，可以发现上述结果中唯一具有具体地址的第 1～4 节分别为 .text, .reginfo, .MIPS.abiflags, .rodata，而它们的 Flg 位都含有 A 标识（Allocate），表示在程序运行的过程中需要为这些节分配内存空间。\n左脚踩右脚上天 # 我们自己完善的 readelf 工具是无法解析自身的。其实，查看 elf.h 头文件便知，我们的程序仅支持 ELF 32 位的程序解析。事实上，我们的程序仅支持 ELF 32 位 小端顺序的程序，如果解析大端顺序的程序，那么会提示段错误。\n真正的 readelf 程序依靠 ELF 头的信息，实现了架构无关性和字节序兼容性，使得这个工具可以解析几乎所有的 ELF 文件。\n当我们运行 readelf -h $(which readelf) 来让 readelf 解析自身时，这个可执行程序被加载到内存中，同时它本身作为被解析的文件也被加载到内存中，二者的性质是不同的，因而可以实现自举。\n我们自己完善的 readelf 工具是在 x64 环境下编译的，其自身是 64 位程序。所以，想要实现我们的 readelf 工具的自举，只需要把我们的程序编译成 32 位程序运行即可。由于在 Ubuntu 上 gcc-multilib 与 gcc-mips-linux-gnu 存在冲突，我们没办法直接使用 -m32 参数编译出 32 位程序，只能通过 mipsel-linux-gnu-gcc 来把程序编译为 mips32 环境下的 32 位小端顺序的 ELF 文件，然后使用 qemu 运行：\nsudo apt install gcc-mipsel-linux-gnu qemu-user mipsel-linux-gnu-gcc main.c readelf.c -o readelf -static qemu-mipsel readelf readelf 如此便可以让我们自己的 readelf 工具解析自己了。\nThinking 1.3 内核入口地址的问题 # 这个问题问的莫名其妙，很容易让不明所以的同学混淆硬件上电时复位地址和内核入口地址两个概念。还是来梳理一下内核的启动流程。\n内核启动流程分析 # 系统在上电之后，CPU 会跳转到复位地址 0xbfc0_0000。这是一个虚拟地址，位于 kseg1 中，因而对应的物理地址为（虚拟地址去掉高三位得到的）0x1fc0_0000。这个地址即硬件上已经烧写好的 BIOS 的启动地址，BIOS 将内核文件加载到内存中， 然后跳转到 Linker Script 中定义的 ENTRY(__start) 位置，这就是内核入口了。\n所以内核入口地址和上电启动地址根本就是两个概念：前者被 Linker Script 确定，后者被硬件架构确定。上电启动地址是一切的开始，内核入口地址是硬件与软件的分割线。\n上机 # exam # 考的是 vprintfmt 中 %k 自定义参数的实现，比较简单。\nextra # 考的实现是 fmemprintf 和 fmemopen、fseed、fclose 四个函数的实现。\n","date":"24 March 2025","externalUrl":null,"permalink":"/posts/oslab1/","section":"归档","summary":"","title":"OS Lab1 实验报告","type":"posts"},{"content":"","date":"24 March 2025","externalUrl":null,"permalink":"/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","section":"标签","summary":"","title":"操作系统","type":"tags"},{"content":" 你在强测中获得了 59.9668 分的好成绩...\n前言 # 第一单元的作业围绕表达式解析与括号展开这一主题，让我们体会了面向对象程序设计的思想与实现。\n处理这一个问题的基本流程为：\nflowchart LR 输入 --表达式--\u003e 预处理 预处理 --表达式--\u003e 词法分析 词法分析 --Token 流--\u003e 语法分析 语法分析 --AST--\u003e 语义分析 语义分析 --表达式--\u003e 输出 先来讲讲中间四个步骤用来做什么。\n预处理 # 按照形式化表述，输入的表达式也许会非常的烦人。它可能会在中间夹着许多的空格、连续的符号和前导零等等，而这些冗余部分我们将在预处理阶段进行处理。\n其实，如果后面的词法分析和语法分析阶段完全是严格按照形式化表述搭建的，那么预处理只是一个可有可无的阶段。但我认为这一阶段的优势主要在于降低调试的复杂度：\n在进入分析阶段之前就对表达式进行预处理，这样单步调试的时候可以少摁几次键盘/鼠标。 如果在后面阶段进行处理但是出锅了，就需要逐层去确定问题的位置，增加了调试的困难程度。 预处理阶段算是对词法分析阶段的一个小小的提炼，降低了后面阶段的复杂度。\n词法分析 # 词法分析 (Lexical Analysis) 是将输入的字符串转换为 Token 序列的过程。\n类似汉语、英语这些语言存在的字词句段篇的概念，我们也可以对数学表达式进行类似的划分，便于计算机去理解这一长串的表达式。试想我们一开始学习加减乘除的时候，也是需要先建立对各种数学符号的认知：这是数字、这是计算符号……计算机也不例外。按照词法规则对输入的表达式字符串进行处理，是一次化整为零的过程，同时这个“零”也不是简单的单个字符，而是一个有意义的 Token。\n语法分析 # 语法分析 (Syntax Analysis) 基于词法分析的结果，构建表示表达式结构的语法树。\n无论是最开始的字符串表达式，还是经过词法分析处理得到的 Token 序列型表达式，都是符合阅读顺序的形式。事实上我们在计算表达式的过程中按照的是表达式的计算顺序：比如乘除的优先级高于加减、括号内的部分先进行计算，等等。构建表达式树，便是将阅读顺序的表达式结构，转为符合计算顺序的表达式结构，方便我们进一步进行计算处理。同时，树这一数据结构具有天然的递归性质，方便我们以递归下降法对表达式进行解析、计算和处理。\n语义分析 # 语义分析 (Semantic Analysis) 确定表达式的实际含义并执行计算。\n这三个分析阶段其实是一个理解的重点。究竟什么是词法分析，什么是语法分析，什么是语义分析，如果没有学过编译原理，一开始上来肯定是晕头转向。我觉得还是首先要理清楚整个程序的执行流程以及每个流程阶段该做什么事情，才能依次去完成代码的编写。\n有了基本的流程设计，接下来就是根据各次作业的迭代要求，逐渐去丰满流程的细节。第一次作业的架构是较为清晰、易于理解的；等到了之后的作业，出于时间和能力的有限，架构难免变得臃肿，也就无可奈何了。\nhw_1 亮剑 # 架构设计 # 参考诸多往届学长的设计，特别是 zyt 学长的笔记，我最终版本实现的架构设计如下：\n整体设计分为前端和后端两个部分（这两个部分是我画图的时候突然想到的点子，写代码前没有想这么多 hhh）。前端负责输入到语法分析部分的流程，后端负责语法分析到语义分析部分的流程，最后再将结果交由前端输出。\n前后端的思想，我原本以为只是存在于 Web 开发之中的。然而寒假学习龙芯杯相关知识，阅读往届优秀代码，才发现所谓处理器也有前后端结构。我觉得简单来说，前端就是输入输出，后端就是处理。有时候为了控制后端的复杂度，会将一部分简单的处理提到前端，某种意义上可以称作“预处理”。从这个意义上来说，流程中的“预处理”、“词法分析”、“语法分析”都属于前端部分的预处理了——占据代码编写复杂度和运行时时空复杂度的大头是语义处理。\n为了维护 MainClass 类的简洁程度，整个 MainClass 类只负责输入和输出，中间的处理的详细过程通过 processInput() 调用 parse.Converter 类进行处理。（其实真正意义上的前端只有 MainClass 类吧）\n早在高一之前，学校有意培养我们班的信息学竞赛，请了几个老师给我们上网课。当时老师教的 parseIn()，core()，writeOut() 三件套被我们一顿嘲讽，现在回旋镖打到了我自己身上……不过总的来说，竞赛追求的是快速编码解决问题，强调的是数据结构与算法；现在学习面向对象程序设计，我们更应该注重体会当中的架构设计，这时候“三件套”反倒成为某种“精髓”了。\n两种体系 # 起初，我是想着将表达式解析为树的结构之后，直接调用解析好的 Expr 对象的 toString() 方法，递归调用其子节点的 toString() 方法进行输出。然而这一架构不能很好地处理化简的要求，基本上是要大大增加 ast 中各个类的设计复杂度。参考学长的设计之后，我认为将 AST 转换为 Poly-Mono 体系再进行处理、输出，这一架构具有良好的可扩展性和可维护性，理解和实现也都非常方便，所以采取了这一设计。\n这种转换有很大的优势：\n实现了模块化与关注点分离。AST 树负责表达式的语法表示，Poly-Mono 体系负责化简与代数计算。 思维复杂度低。换句话说就是设计简洁。在第一次作业中，所有的表达式都可以表示为 $\\sum{term}$，所有的项都可以表示为 $a*x^b$。将原有的 AST 树结构化为“标准项”和“标准项集合”的结构，降低了化简和计算的复杂度。同时，将 AST 转化为 Poly-Mono 体系也极为简单，一看代码便知。 标准项 # 总结出这种设计的人们真是天才！\n这是一种化零为整的思想，把 AST 中“表达式-项-因子”这样的解析结构转换为“多项式-项”这样的计算结构，便于化简和计算。\n此处待完善…… ","date":"18 March 2025","externalUrl":null,"permalink":"/posts/oounit1/","section":"归档","summary":"","title":"OO Unit1 总结","type":"posts"},{"content":" 我是说点文件，不是让你点文件\n前言 # 使用 OS 跳板机，为了上机时更高的效率，大家总是会想着能不能配置好自己的环境。然而 OS 一结束跳板机一回收，这些配置也就消失了，我觉得非常可惜。参考之前看过的一些仓库，我们可以对自己家目录下的配置文件进行版本管理，并上传到 GitHub 远程仓库以保存。\n我的 dotfiles # 展示出我的配置以供大家参考，已经上传到 GitHub 上，这样我其他的机子都可以共享使用。详见 tangsongxiaoba/dotfiles。\n首先我们可以发现，大部分家目录下的配置文件都是以 . 开头的。这是因为以 . 开头的文件和文件夹默认是隐藏的，除非你在 ls 的时候加入 -a 参数。于是我们可以着重管理这些文件。常见的配置文件有：\n.bashrc 是用户登录到系统时自动执行的脚本。在 OS 跳板机上叫做 .bash_profile，此外 Linux 中还有其他登录时自动执行的脚本，我并没有系统学习过，有了解过的大佬还请教教我 orz .vimrc 是用户对 vim 的配置文件。 .tmux.conf 是用户对 tmux 的配置文件。 .ssh/ 是用户存储的 ssh 登录相关的密钥等目录。我不知道对 .ssh/ 进行版本管理会不会有什么隐私风险，所以没有去管理它。 .config/ 是用户存储的一些常用配置文件等目录，也许并不存在。 我的这份配置是这样工作的：\n在 dotfiles/ 目录下创建一个不含 . 的文件或者文件夹，比如要管理 ~/.vimrc，就创建一个 vimrc；要管理 ~/.config/，就创建一个 config/。至于为什么要去掉 .，我想的是，带 . 的文件应该是配置文件等，不带 . 的文件应该是需要显式管理的文件。 运行 run.sh。这会将 dotfiles/ 复制到 $HOME/.dotfiles/（覆盖），然后自动将 $HOME/.dotfiles/ 下的所有非隐藏的文件和文件夹链接到家目录下对应的隐藏文件和文件夹。也就是说，对于每个应链接的文件/文件夹，执行 ln -sf /path/to/xxx ~/.xxx 创建一个 .ignore 文件以管理需要被忽略的文件。因为这是一个项目，应有一份 README，而 README.md 文件是我们不希望链接到家目录下的。因此，在 .ignore 和 .ignore.local 文件中添加的项则不会进行链接。.ignore.local 是被 .gitignore 忽略了的，因此不会被上传到 Git 中，作为本地配置。 在链接文件夹的过程中会先检查该文件夹下是否有 init.sh，若有则会先执行再链接。目前这个做法是为了给 bin/ 目录下的可执行文件赋予可执行权限。 这里进行配置的关键文件是项目根目录下的 run.sh 脚本。这脚本一部分是我自己写的，一（大）部分是 AI 生成的。bash 还是太难写了（\nbin/ 目录下的 init.sh 会将该目录下所有的文件进行检测，如果是可执行文件/脚本则赋予 755 权限。run.sh 会自动检测每个目录下是否存在 init.sh，并会在链接之前先行执行它。\n目前这份脚本在我的跳板机上、我的 WSL 上和我自己的 Linux 机器上都可以正常运行，如果有虫欢迎来捉（orz\n跳板机部署方法 # 注意，进行如下操作时请先备份好你自己的配置文件！！！！！！！！！！\n我的脚本是强制覆盖家目录下的对应配置文件的，请先备份！！！！！！！\n在网页端，我们可以通过“文件管理”对跳板机的文件进行上传/下载。“文件管理”进行上传/下载的目录是跳板机下的 /2337xxxx 目录，对应我们各自的学号。我们可以把这个项目上传到跳板机，然后 cd /2337xxxx/dotfiles，并在该目录下执行 bash run.sh，会自动将整个文件夹复制到家目录下的 .dotfiles/，并对文件夹中的所有配置文件（夹）进行链接。\n然而，如果你像我一样进行版本管理的是 bashrc 而非 bash_profile（窃以为前者比后者更常见），跳板机并不会在登录时自动执行 .bashrc 文件，而是自动执行 .bash_profile 文件。为此，可以执行 ln -sf ~/.bashrc ~/.bash_profile 来链接 bashrc 文件。\n后续改进 # 可以考虑怎么管理 .ssh/ 等具有隐私信息的文件或目录。 可以更进一步，考虑使用声明式配置的方法对整个 OS 进行管理，所谓 OS as Code。参考 NixOS。 ","date":"15 March 2025","externalUrl":null,"permalink":"/posts/dotfiles/","section":"归档","summary":"","title":"使用 Git 管理家目录下的配置文件","type":"posts"},{"content":"","date":"15 March 2025","externalUrl":null,"permalink":"/tags/%E6%8A%98%E8%85%BE/","section":"标签","summary":"","title":"折腾","type":"tags"},{"content":"","date":"15 March 2025","externalUrl":null,"permalink":"/tags/%E9%85%8D%E7%BD%AE/","section":"标签","summary":"","title":"配置","type":"tags"},{"content":" 谁不喜欢免费的网络呢？当然是买单的人不喜欢。\n安装配置 Proxmox VE # 安装过程略。\n校园网自动登录 # 从 tangsongxiaoba/buaa_login 下载 Linux 下的校园网登录可执行文件，改名为 buaa_login 并赋予可执行权限，然后移动到 /usr/bin 目录下。另外，在 /opt 下创建一个 buaa_login.sh，输入学号密码，用于登录。\nchmod +x buaa_login mv buaa_login /usr/bin echo \u0026#39;buaa_login -i 23xxxxxx -p xxxxxxx\u0026#39; \u0026gt; /opt/buaa_login.sh chmod +x /opt/buaa_login.sh 编写 Systemctl 服务和定时执行脚本 buaa_login.service 和 buaa_login.timer，放到 /etc/systemd/system 下。\n# buaa_login.service [Unit] Description=Run BUAA Login [Service] Type=oneshot ExecStart=/opt/buaa_login.sh # buaa_login.timer [Unit] Description=Run buaa_login.service every 15 mins [Timer] OnBootSec=10s OnUnitActiveSec=15min Persistent=true [Install] WantedBy=timers.target 然后重载 systemctl，并设置开机自启定时脚本\nsystemctl daemon-reload systemctl enable --now buaa_login.timer systemctl status buaa_login.service 这里只需要自启 timer，--now 参数可以让它立刻启动一次。然后查看一下运行状态，如果没报错就是正常运行了。\nchsrc 一键换源 # 运行以下脚本以一键安装 chsrc\ncurl https://chsrc.run/posix | bash 安装后，运行 chsrc set debian bfsu 以更换 Debian 软件源。这里使用北京外国语大学开源软件镜像站。\n大概率会报错，不用管错误。因为没有禁用 security 源和 proxmox 源，更新缓慢。\n编辑 /etc/apt/sources.list，禁用其中的 security 源。\n运行 pvetools 以快速配置 PVE # 一键无脑安装 pvetools\nsver=`cat /etc/os-release|grep VERSION_CODENAME|awk -F \u0026#39;=\u0026#39; \u0026#39;{print $2}\u0026#39;` \u0026amp;\u0026amp; echo \u0026#34;nameserver 8.8.8.8\u0026#34; \u0026gt;\u0026gt; /etc/resolv.conf \u0026amp;\u0026amp; rm -rf pvetools \u0026amp;\u0026amp; echo \u0026#34;deb http://mirrors.ustc.edu.cn/proxmox/debian/pve/ $sver pve-no-subscription\u0026#34; \u0026gt; /etc/apt/sources.list.d/pve-no-sub.list \u0026amp;\u0026amp; sed -i \u0026#39;s|deb|#deb|\u0026#39; /etc/apt/sources.list.d/pve-enterprise.list \u0026amp;\u0026amp; echo \u0026#34;\u0026#34; \u0026gt; /etc/apt/sources.list.d/ceph.list \u0026amp;\u0026amp; export LC_ALL=en_US.UTF-8 \u0026amp;\u0026amp; apt update \u0026amp;\u0026amp; apt -y install git \u0026amp;\u0026amp; git clone https://github.com/ivanhao/pvetools.git \u0026amp;\u0026amp; echo \u0026#34;cd /root/pvetools \u0026amp;\u0026amp; ./pvetools.sh\u0026#34; \u0026gt; pvetools/pvetools \u0026amp;\u0026amp; chmod +x pvetools/pvetools* \u0026amp;\u0026amp; ln -s /root/pvetools/pvetools /usr/local/bin/pvetools \u0026amp;\u0026amp; pvetools 按照提示快速设置即可。\n其他配置 # 从 GitHub 上获取 tangsongxiaoba/dotfiles，然后按照仓库内的 README 运行以更新家目录下的配置。\n安装配置 ImmortalWrt # 编译安装固件 # 在官网上下载immortalwrt-imagebuilder-24.10.0-x86-64.Linux-x86_64.tar.zst，解压得到文件夹。\n安装依赖。\n# Ubuntu 24.04 sudo apt update sudo apt install build-essential clang flex bison g++ gawk \\ gcc-multilib g++-multilib gettext git libncurses5-dev libssl-dev \\ python3-setuptools rsync swig unzip zlib1g-dev file wget qemu-utils genisoimage WSL 下进入到目录后，运行以下脚本。\nexport PATH=$(echo \u0026#34;$PATH\u0026#34; | sed \u0026#39;s; ;;g\u0026#39;) # to remove whitespace in path temply make clean make image \\ PROFILE=\u0026#39;generic\u0026#39; \\ PACKAGES=\u0026#34;kmod-mt7922-firmware kmod-mt7921e kmod-mt7921-common kmod-mt7921-firmware kmod-mt792x-common hostapd hostapd-common hostapd-utils iw-full iwinfo luci-app-argon-config luci-app-openclash luci-i18n-argon-config-zh-cn luci-theme-argon openssh-server openssh-sftp-server pciutils wireless-regdb wpa-supplicant\u0026#34; 第一步是为了将 Windows 中的 Path 环境变量中的空格临时除去，否则编译过程中会报错。\nPROFILES 选择 generic 即可，PACKAGES 中添加自己想要安装的软件包。\n编译好后的固件放在 bin/targets/x86/64 目录下，选择 immortalwrt-24.10.0-x86-64-generic-squashfs-combined.img.gz 作为镜像。\n将解压后的镜像上传到 pve 中。创建一个虚拟机，假设编号为 100。\n使用命令 qm importdisk 100 immortalwrtxxx.img local-lvm 来将镜像导入到 pve 中。\n然后，使用 qm set 100 --scsi0 local-lvm:vm-100-disk-0,iothread=1,size=1024M 来将镜像配置为虚拟机的一块磁盘。\n记得为虚拟机设置启动选项，随后就可以正常启动虚拟机进行配置了。\n配置 ImmortalWrt # 配置网络设备 # 如果固件安装正确，应该可以看到直通的网卡已经被 ip link 正确识别。我的配置是在虚拟机内，用 eth0 进行连接 WAN，eth1、eth2 和 phy0-ap0 用 br-lan 进行桥接，统一管理 LAN 口。\n编辑 /etc/config/network，大致设置如下：\nconfig device option name \u0026#39;br-lan\u0026#39; option type \u0026#39;bridge\u0026#39; list ports \u0026#39;eth1\u0026#39; list ports \u0026#39;eth2\u0026#39; list ports \u0026#39;phy0-ap0\u0026#39; config interface \u0026#39;lan\u0026#39; option device \u0026#39;br-lan\u0026#39; option proto \u0026#39;static\u0026#39; option ipaddr \u0026#39;192.168.100.1\u0026#39; option netmask \u0026#39;255.255.255.0\u0026#39; config interface \u0026#39;wan\u0026#39; option device \u0026#39;eth0\u0026#39; option proto \u0026#39;dhcp\u0026#39; 随后运行 /etc/init.d/network restart 重启网络。\n配置校园网 # 从 GitHub 下载适合 openwrt 的校园网登录程序。\nmv login_xxx /usr/bin/buaa_login chmod +x /usr/bin/buaa_login mkdir /opt echo \u0026#39;buaa_login -i 23xxxxxx -p password\u0026#39; \u0026gt; /opt/buaa_login.sh chmod +x /opt/buaa_login.sh echo \u0026#39;*/15 * * * * /opt/buaa_login.sh \u0026gt;/opt/buaa_login.log 2\u0026gt;\u0026amp;1\u0026#39; \u0026gt; /etc/crontabs/root /etc/init.d/cron restart 然后要把 DNS 服务器写一下：\necho \u0026#39;nameserver 202.112.128.50\u0026#39; \u0026gt; /etc/resolv.conf 最后执行 /opt/buaa_login.sh 就可以连校园网了。\n防火墙设置 # openwrt 的防火墙默认是 wan 口不准入，因此 firewall 开启之后，ssh 和 学校内网 ip 访问网页是不通的。可以选择编辑 /etc/config/firewall，将 wan 口 IN 的 REJECT 改为 ACCEPT。\n然后重启防火墙：/etc/init.d/firewall restart\ndnsmasq 设置 # 之后的设置在网页端进行，没有什么压力。但是 dnsmasq 需要将本地域名后缀删除，否则 Clash 设置后无法正常解析。在过滤器界面，需要取消重定向保护，支持 Clash 开启后访问校园内网。\n","date":"14 March 2025","externalUrl":null,"permalink":"/posts/net4dorm/","section":"归档","summary":"","title":"在宿舍配置网络环境","type":"posts"},{"content":" 以我自己在 hw_2 的一次时间优化为例\n前言 # 室友 @Kie-Chi 发现了这个好用的工具，但他忙着性能优化没空写，所以我来写（\nProfiler，通常就是指程序的性能分析工具，可以帮助我们分析和优化代码的性能。（废话）\nIntelliJ Profiler # IntelliJ Profiler 是 JetBrains 为 IDEA Ultimate 版提供的性能分析工具，用于监控和优化程序的性能。（废话 x2）\n不过要注意，这个工具的使用需要 Ultimate 版本，如果是免费的 Community 版本是不支持的，所以如果你想使用，请先参照网上的教程申请 IDEA Ultimate 版。\n接下来，我会以我的一次（时间）性能优化为例，向各位展示这个工具的妙用。\n以下案例基于我的真实优化案例，但是略有加工，具体情况我会在结语说明。\n前情提要 # xx年x月x日x时x分，tsxb 完成了 hw_2 的基本编写，然而他的程序还是拜倒在水群大佬搓的数据下：\n1 f{n}(x)=1*f{n-1}(sin(sin(sin(x))))+0*f{n-2}(x) f{1}(x)=sin(sin(sin(sin(x)))) f{0}(x)=sin(sin(sin(sin(x)))) f{5}(f{0}(f{0}(f{0}(f{0}(f{0}(f{0}(x))))))) 啊，怎么优化啊。他心里很急切，然而他的在 hw_2 开启后的一个小时内就完成了基本编写并在第二天就完成了绝大部分长度优化并且程序还跑的巨快巨正确没有什么错误的巨佬中的巨佬的室友一脸淡定的回答道：\n用 IntelliJ Profiler 分析一下。\n于是 tsxb 开始研究这个玩意……\n22 分钟可以喝 11 升水 # 要想运行 IntelliJ Profiler，在 IDEA 界面下找到右上角运行旁的小三点，点击后在展开的菜单栏下找到“使用 IntelliJ Profiler 分析……”\n点击后，IDEA 会自动进入运行界面，同时 IntelliJ Profiler 已就绪。输入数据后（也可以使用重定向输入，见结语）就可以喝杯茶等你的程序跑完~\n上帝视角：优化之后我的程序运行就出结果了，现在我签出到优化前的这次提交，跑了n久也没等到结果……\n……\n……\n事实上，在 21 分 33 秒之后 tsxb 洗完澡回到了寝室，然后发现他的程序还没跑完。。。\n这不经让他感叹，到底是这个程序跑得更慢，还是他衬衫背后那段代码跑得慢。\n没关系的，虽然你程序写的不好，但是你球打的也烂啊，hhhh555。\n好吧，虽然界面上显示有“停止并显示结果”的功能，但 tsxb 尝试了之后并没有效果。无奈之下他只好选择另一组数据来测试。\n1 f{0}(x) = cos(cos(cos(x))) f{1}(x) = cos(cos(cos(x))) f{n}(x) = 1*f{n-1}(cos(cos(x)))+ 1*f{n-2}(cos(cos(x))) f{5}(cos(cos(cos(cos(cos(cos(cos(cos(x))))))))) 这次他跑的还算比较还行很快，经过 0.13333 分钟后程序就运行出了结果。此时左侧出现了一个通知：“分析器数据已就绪”，tsxb 打开之后得到了以下界面：\n真是太壮观了！然而他看不懂。于是他的大牛室友向他介绍了一种简单方法。\n简单方法 # 点击你的主类，可以在左侧看见每个方法或者语句的执行时间。\n单击这个时间，可以选择想要查看的方法，然后层层点击进去，就可以找到影响时间的“缓慢杀手”。\n在 tsxb 的 Mono 类和 Poly 类下，他发现了一个问题：他的 toString() 方法运行的耗时最长。\n这里展示的是他的 Poly 类的 toString() 方法，可以看到实现得相当冗长。下面那一抹红则是调用了 Mono 的 toString() 方法，而他的 Mono 类的 toString() 方法又调用了 Poly 类的 toString() 方法……\n并且在这一过程中，他没有在这方法的内部发现有其他更加耗时的操作。正所谓日积月累，水滴石穿，人一赖床就日上三竿，在 Mono 类和 Poly 类的 toString() 方法的嵌套调用中，tsxb 成功地 CTLE 了。\n解决问题 # 既然找到了问题，那么对症下药即可。tsxb 发现，他的 Mono 类和 Poly 类的实现都是不可变类——所谓不可变类，tsxb 粗浅的认为就是状态不可更改的类，一旦该类对应的对象被创建，其所有字段的值都被固定下来，无法进行修改。\n这就好办了！既然 Mono 类和 Poly 类是不可变的，它们从一开始到结束，toString() 方法生成的字符串也应该是不变的。那么当第一次调用了 toString() 方法，将生成的字符串缓存之后，下次再调用不就可以直接用了吗？\ntsxb 觉得：Damn! I\u0026rsquo;m so fxxking smart! 于是他就开始了重构。完成了修改之后，他再次对这个样例进行了测试：\n轻松秒杀~\n进阶方法 # 实际上 IntelliJ Profiler 还有更多强大的功能。\n火焰图：可以可视化程序的调用堆栈，并查看它随着时间的变化。栈框架越宽，方法执行时间越长。彩色块显示的是本地代码，而灰色块是 Java 标准库的一些代码。看 tsxb 第一次运行结果的火焰图，不可不谓是众人拾柴火焰高。 调用树：可以显示方法使用的 CPU 时间百分比，以及具体的方法执行路径。不断展开选项，你就可以看到一条消耗时间的关键路径（该死的 CO 还在追我）。由于我们是递归调用层次，这一关键路径非常长，而且占用时间百分比是随着层次的展开一点一点减少的。 方法列表：可以显示按运行时间排序的方法，这里就可以跳过递归，很快找到耗时最长的方法。 此外还有时间轴、事件等视图，不一一介绍了，进阶嘛，要留着自己探索（\n结语 # 其实我这次调优的实际情况比这要复杂一些。我先是实现了哈希缓存——是的，不可变对象的哈希当然也不变，然后才想到字符串也可以做缓存。在这期间，我还意外发现我的 powPoly() 方法（就是把一个多项式进行乘方运算）实现非常缓慢，原因竟然是我画蛇添足，给 powPoly() 实现了快速幂算法……\n为什么快速幂算法在这里反而会更慢呢？虽然快速幂算法能够优化乘法的次数，但是我忽略了单次乘法的时间——对于多项式来说，一个长的多项式乘以一个短的多项式，明显是要比两个中等的多项式相乘所花的时间要短的。嗯，应该是吧，没有细想，我只是拿等周长的长方形和正方形的面积大小做了个类比。所以快速幂反而变成蜗牛幂了（\n此外，其实我的 Poly 类并非一个完全的不可变对象。我的 Poly 类实现了一个 addMono() 的方法，会更新它的 HashMap\u0026lt;MonoKey, Mono\u0026gt; monoMap 这一字段。然而之后我详细查看了我其他调用 addMono() 的方法，都是在其他方法中创建了一个新的 Poly 对象，并在返回前往里面加 Mono 对象，这一过程中并没有用到该 Poly 对象的哈希或者字符串。所以为 Poly 类设置缓存能运行成功，只是侥幸。\n不过，如果想要为上面这种可变类设计缓存也不是不行，加上一个脏标记即可（怎么还有线段树的味道）。我的做法是，创建几个布尔变量来表示对缓存的脏标记，如果标记缓存为脏则说明需要重新计算缓存，调用相应方法即可；否则直接调用缓存。在重新计算缓存的方法的结尾，和修改对象的方法的开头，可以加上对脏标记的修改，这样大概就可以了。\n关于脏标记我也不太懂，如果有大佬实现了，希望能发出来让大家瞻仰一下）\n关于 IDEA 的重定向输入输出的问题，可以在右上角运行附近找到“编辑配置”选项，里面的选项中可以选择重定向输入以及将控制台输出保存到文件，进行相应的配置即可。此外，虚拟机参数也可以如图加上 -Xms768m -Xmx768m 的选项，以将程序运行内存限制在 768M 以内，符合课程组强测的要求。（玩过 mc 的应该都懂吧）\n好了，这次分享就到这里，希望你能喜欢，并有所收获！\n","date":"11 March 2025","externalUrl":null,"permalink":"/posts/intro2profiler/","section":"归档","summary":"","title":"IDEA Profiler 在 OO 课程中的使用方法","type":"posts"},{"content":" Hello OS!\nThinking 0.1 Git 的使用 1 # 操作流程 # # init mkdir ~/learnGit \u0026amp;\u0026amp; cd ~/learnGit git init . # 1 touch README.txt git status \u0026gt; Untracked.txt # 2 echo \u0026#34;hello world!\u0026#34; \u0026gt; README.txt git add . git status \u0026gt; Staged.txt # 3 git commit -m \u0026#34;23371263\u0026#34; cat Untracked.txt cat Stage.txt # 4 echo \u0026#34;hello git!\u0026#34; \u0026gt; README.txt git status \u0026gt; Modified.txt cat Modified.txt 流程分析 # Git 将文件分为四种状态：untracked，unmodified，modified，staged。#1 的文件处于 untracked 的状态。#2 的文件在 add 之后变成了 staged 的状态，并在 #3 commit 之后变成了 unmodified 的状态。#4 的文件在修改之后，变成了 modified 的状态。\n这是一种有限状态机的设计，用图示可以表示为如下：\nstateDiagram [*] --\u003e untracked untracked --\u003e staged : git add file staged --\u003e unmodified : git commit unmodified --\u003e modified : edit file modified --\u003e staged : git add file staged --\u003e modified : edit modified --\u003e unmodified : git checkout -- file staged --\u003e untracked : git rm --cached file modified --\u003e untracked : git rm file VS Code 的自动暂存 # 平时我们在使用 VS Code 的时候，在一个 Git 仓库中，VS Code 会自动把新建的文件（包括修改的内容）提交到暂存区，自动变成 staged 状态。我们输入提交消息并 commit 之后，文件就变成了 unmodified 的状态。也就是说，VS Code 将这四种状态化简为了两种状态，而自动帮我们处理了其他两种状态与这两种状态之间的转换：\nstateDiagram [*] --\u003e staged staged --\u003e unmodified : commit unmodified --\u003e staged : edit 我觉得这非常方便，从多种状态转换的路径中抽离出最常用的两条路径供用户手动处理，而自动处理其他部分的内容，是一种非常自然的设计。\nIDEA 的文件状态转换 # 反观 IntelliJ IDEA，没有像 VS Code 这样流畅的设计，它的文件状态的转换逻辑和 Git 的设计相同，没有进行简化。所以我们在 IDEA 里新建一个文件，默认是 untracked 状态的。需要在版本管理页面手动为文件打勾，表示将其暂存，才能提交这些文件。多一种操作当然多一些自由度，但是也增加了操作的复杂性。\n这样的文件状态转换的方式，与 .gitignore 文件相结合时，也会遇到一些问题。.gitignore 忽略的是 untracked 状态的文件。如果你打开了 IDEA 的自动暂存功能，它就真的把新建的文件提交到暂存区，然后不管不顾了——也就是说，如果你在将某一文件（或者文件类型）加入.gitignore 之前就创建了这一文件（或者这一类型的文件），那么这个文件仍然会被 Git 追踪。VS Code 对待的方式则不同——如果你在创建之后把文件加入了 .gitignore，那么即使它被暂存了，它依然会被 VS Code 认为是需要忽略的文件，于是它会被清出暂存区，并设置成被忽略的状态。只有被提交过的文件，VS Code 才不会去将它忽略。\n总的来说，虽然 IDEA 的逻辑设计与 Git 如出一辙，但我并不认为这是一个好的设计——也许对于 Git 这样的命令行工具来说这种完备性是需要的，但作为一个现代的、智能的 IDE，VS Code（姑且认为它是个 IDE）这种更简洁的方式更加符合直觉。\nThinking 0.2 箭头与命令 # \u0026ldquo;add the file\u0026rdquo;: git add \u0026ldquo;stage the file\u0026rdquo;: git add \u0026ldquo;commit\u0026rdquo;: git commit git add 命令对应的操作是两种：一种是将 untracked 的文件放入暂存区，一种是将 modified 的文件放入暂存区。其实本质上，都是将文件的变化放入暂存区中以记录。\nThinking 0.3 Git 的一些场景 # Git 如何恢复文件 # 以往我的理解是从 Git 的三个区域入手的，但现在我发现也许从文件的四个状态去理解恢复机制会更好。 untracked 的文件被误删，因为它和 Git 还没产生关系，就没法通过 Git 恢复了。 unmodified 的文件被误删，此时它的状态就变成了 modified。我们可以通过 git restore \u0026lt;file\u0026gt; 来将其恢复到 unmodified 的状态。 modified 的文件被误删，状态还是 modified。我们可以把删除也理解为一种修改，而这次的修改（即删除）与上次的修改合并了。所以无论如何，我们也只能通过 git restore \u0026lt;file\u0026gt; 把它恢复到 unmodified 的状态。 另一种理解是，我们上一次的修改尚未被 Git 记录，所以没法通过 Git 恢复上一次修改的部分。 staged 的文件被误删。此时文件的状态变为 modified。此时我们也可以通过 git restore \u0026lt;file\u0026gt; 的方法将其恢复到 staged 的状态。 注意这里是恢复到 staged 状态而不是更早的 unmodified 的状态。如果我们想要（将一个 staged 状态下的文件）恢复到更早的 unmodified 的状态，我们首先需要通过 git restore --staged \u0026lt;file\u0026gt; 来将 staged 状态的文件恢复到 modified 的状态，再通过 git restore \u0026lt;file\u0026gt; 来把它恢复到先前的 unmodified 的状态。 如果 staged 的文件被误删，此时又 git commit 提交了暂存区。已经 staged 的“文件”变成了 unmodified 的状态，但由于删除的操作并未暂存，所以该文件仍处于 modified 的状态。我们还是可以通过 git restore \u0026lt;file\u0026gt; 来把它恢复到 unmodified 的状态。 可以看到，git restore \u0026lt;file\u0026gt; 可以将一个处于 modified 的状态的文件恢复到其上一个状态（unmodified 或者 staged），而 git restore --staged \u0026lt;file\u0026gt; 可以将一个处于 staged 的状态的文件恢复到其上一个状态（modified 或者 untracked）。所谓的误删操作，在 Git 看来就是将文件从其当前状态变为了 modified 状态而已。 如果我们删除了一个文件，并已经通过 git commit 提交了（这还能算是误删吗？），我们也可以恢复其历史版本（如果删除之前我们提交过的话）。可以使用 git log 查看提交的历史记录，确定某一提交有我们所需的文件后，记住其哈希值的前几位，使用 git restore --source=\u0026lt;hashcode\u0026gt; \u0026lt;file\u0026gt; 来恢复该文件。恢复后，该文件会处于 modified 的状态。 事实上在 Git 中我们很难彻底删除一个文件，即便是我们毁灭了某几条提交记录，兴许还有办法把这几条记录给找回。这种高级操作大概也叫 Git 魔法（\n从 Git 的三个区域入手大概也能理清楚 git restore 的逻辑，但我想应该比上面这种方法要复杂。\nGit 如何删除文件 # 这个问题从 Git 的三个区域分别讲更好。Git 复杂的原因之一就是有很多个角度去看待它的操作，而且不同操作的最佳视角还不一样。\n从工作区删除一个文件。直接使用系统的 rm 就好。 从暂存区删除一个文件。我们可以使用 git rm \u0026lt;file\u0026gt; 命令。这个命令就是 Git 版 rm，它会同时将工作区和暂存区的这个文件全部删除——前提是这两份版本相同。也就是说，如果你暂存了这个文件之后又修改了它，使用这个命令时 Git 就会发出警告并终止操作。要想强制执行，加 -f 即可。 如果想保留工作区的文件，而删除暂存区的文件，可以使用 git rm --cached \u0026lt;file\u0026gt;。也就是说，git add \u0026lt;file\u0026gt; 的反义词其实是 git rm --cached \u0026lt;file\u0026gt; ——非常糟糕，对吧？ 如果真要这么说，git rm --cached \u0026lt;file\u0026gt; 和 git restore --staged \u0026lt;file\u0026gt; 是同义词。更糟糕了。 从版本库删除一个文件。这件事情就难办了， 但是使用 Git 的新手又经常遇到这样的问题——经常不检查即将 commit 的代码，而把自己的个人信息或者隐私给提交了。我之前就遇到过这样的问题。下面是我的解决方法，当然可能清除得不彻底。 使用 pip 安装 git-filter-repo 确定泄露信息的格式，比如学号\u0026quot;2337xxxx\u0026quot;，则可以使用 git filter-repo --replace-text \u0026lt;(echo \u0026quot;2337xxxx==\u0026gt;\u0026quot;) 将所有历史提交中的\u0026quot;2337xxxx\u0026quot;替换为空串。如果要删除某个文件，可以使用 git filter-repo --path file --invert-paths 上述的方法也许不够灵活，下面再介绍一种方法： 如果能够确定是最近几次提交中泄露的信息，可以使用 git rebase -i HEAD~\u0026lt;x\u0026gt; 来修改最近 x 次提交。 终端会打开文本编辑器，显示这几次提交的 hash 信息和 commit 消息，将需要修改的提交前的 pick 改为 edit，然后保存退出。 此时工作区会恢复到第一条转为 edit 的提交被提交之前的状态，可以在此时清除信息。 使用 git commit --amend 修改提交消息。 使用 git rebase --continue 继续修改下一条提交。 -这些操作之后，由于你修改了历史提交记录，推送到远程仓库时必须使用 git push --force 来强制覆盖远程仓库的记录。注意 OS 和 OO 的 gitlab 是不支持强制推送的，只有在你自己的 Github 仓库中你才有权利这么做，而如果有别的协作者，他们需要使用 git fetch 和 git reset --hard origin/main 来避免与远程仓库的冲突。 Thinking 0.4 Git 的使用 2 # 操作流程 # cd ~/learnGit #1 touch README.txt echo \u0026#34;Testing 1\u0026#34; \u0026gt; README.txt git add . git commit -m \u0026#34;1\u0026#34; # repeat with commit message \u0026#34;2\u0026#34; and \u0026#34;3\u0026#34; git log #2 git reset --hard HEAD^ git log #3 git reset --hard \u0026lt;HASHCODE_1\u0026gt; # hashcode of commit with message \u0026#34;1\u0026#34; git log #4 git reset --hard \u0026lt;HASHCODE_3\u0026gt; # hashcode of commit with message \u0026#34;3\u0026#34; 分析 # 使用 git reset --hard 命令可以进行版本回退或者切换到任何一个版本。\n使用 HEAD^ 切换到上一个版本 使用 HEAD~\u0026lt;x\u0026gt; 切换到前第 x 个版本 使用 hash 值切换到任意版本 这里可以看到，我们在 #2 中回退到上一个版本，此时执行 git log 会找不到提交消息为\u0026quot;3\u0026quot;的提交记录。如果不是事先记录下它的 hash 值，我们可能无法找到这条记录了。\n事实上并非找不到。可以使用 git reflog 来查看 HEAD 指针移动的历史记录。刚才我们 commit 了三次，随后 reset 一次，这四次指针移动的情况被 git reflog 完整的记录下来，我们就可以通过前三次记录找到提交消息为\u0026quot;3\u0026quot;的提交的哈希值。\nThinking 0.5 echo 的使用 # 操作流程 # echo first # first echo second \u0026gt; output.txt # output.txt: second echo third \u0026gt; output.txt # output.txt: third echo forth \u0026gt;\u0026gt; output.txt # output.txt: # third # forth 分析 # \u0026gt; 用于将命令的输出覆盖到文件中，\u0026gt;\u0026gt; 用于将命令的输出追加到文件中。\nThinking 0.6 文件的操作 # 操作流程 # # command #!/bin/bash touch test echo \u0026#39;#!/bin/bash\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;echo Shell Start...\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;echo set a = 1\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;a=1\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;echo set b = 2\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;b=2\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;echo set c = a+b\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;c=$[$a+$b]\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;echo c = $c\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;echo save c to ./file1\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;echo $c\u0026gt;file1\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;echo save b to ./file2\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;echo $b\u0026gt;file2\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;echo save a to ./file3\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;echo $c\u0026gt;file3\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;echo save file1 file2 file3 to file4\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;cat file1\u0026gt;file4\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;cat file2\u0026gt;\u0026gt;file4\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;cat file3\u0026gt;\u0026gt;file4\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;echo save file4 to ./result\u0026#39; \u0026gt;\u0026gt; test echo \u0026#39;cat file4\u0026gt;\u0026gt;result\u0026#39; \u0026gt;\u0026gt; test bash command \u0026gt; test bash test \u0026gt; result 分析 # 单引号用来引用完全的“字面值”的字符串。所有在单引号中的内容都会被原样保留，不会进行替换或者转义。 双引号用来引用字符串，但允许变量和命令的替换或转义。 反引号用于命令替换，即先执行反引号包含的命令，再将该命令的输出替换到当前位置。等价于$()。 上机 # 题量很大，勉强做完。知道思路，不懂实现。bash不会，完完蛋蛋。\n","date":"11 March 2025","externalUrl":null,"permalink":"/posts/oslab0/","section":"归档","summary":"","title":"OS Lab0 实验报告","type":"posts"},{"content":"打算尝试使用一下 NixOS，来做声明式配置系统的尝试。\n","date":"12 February 2025","externalUrl":null,"permalink":"/moments/2025_02_12_21_55/","section":"动态","summary":"","title":"2025_02_12_21_55","type":"moments"},{"content":"专注！Attention is alllll IIIII neeeeed.\n","date":"9 February 2025","externalUrl":null,"permalink":"/moments/2025_02_09_14_14/","section":"动态","summary":"","title":"2025_02_09_14_14","type":"moments"},{"content":"我决定放弃学习 SpinalHDL。\n为什么坚持了大半个寒假，最终我要选择在还有 8 天时间返校的时候放弃学习它呢？我的理由如下。\nSpinalHDL 的文档太少了。它只有官方给出的一份文档，对于语言当中的很多特性，我只能从中做粗浅的了解，而不能详细的掌握运用。 我的时间不够。我原本的目标是在寒假快速掌握 SpinaHDL，并搭建一个 CPU。但到如今，我在学习这门语言的过程中处处受阻。也许学习它的一些项目库的代码是我应该做的，但留给我的时间已经不多了。 我前几天尝试过训练一个 SpinalHDL 方面的专家 AI，但没有成功，并且浪费了很多时间。 sbt sucks. SpinalHDL(Scala) 所使用的编译工具 sbt 不是很好用。在 VSCode 上，你每次点击 run 生成的 Verilog 代码并不是最新的，和编辑器里的代码总有一点小小的时差。这也许是 sbt 和 VSCode 的配合（比如插件 Metals 的问题）并不是很好，或者是 sbt 编译速度太慢导致的。总之不是特别聪明。 我今天看到 HN 上对 SpinalHDL 一类语言的讨论，有个人的观点说服了我。原文是对 Chisel 的讨论，但两者差不多。他说：“硬件开发的真正成本在于硬币的另一面，即硬件验证。”虽然我可以通过 SpinalHDL、Chisel 之类的语言大大节省我的硬件设计的时间，但在验证方面，我不能完全保证它生成的 Verilog 代码一定是符合程序员逻辑的。为此我在验证阶段需要花费的时间比 Verilog 语言更多。这一点原因是今天促使我放弃学习 SpinalHDL 的最大原因。 在这个寒假的剩余时间里，我决定直接使用 Verilog 开始编写 CPU，努力把进度赶上。之后，我打算学习 System Verilog。Vivado 支持 System Verilog，为了更新更好的硬件描述语言特性，我就没有必要再用旧的 Verilog 了。寒假编写的 CPU 也会慢慢用 SV 改进。\n","date":"8 February 2025","externalUrl":null,"permalink":"/moments/2025_02_08_21_09/","section":"动态","summary":"","title":"2025_02_08_21_09","type":"moments"},{"content":" 第一条动态！\n","date":"19 January 2025","externalUrl":null,"permalink":"/moments/2025_01_19_23_29/","section":"动态","summary":"","title":"2025_01_19_23_29","type":"moments"},{"content":" 可能是，可能不是，全面准备吧。\n这是我 24 秋学习计组课程的心得总结，希望对你有所帮助。我主要从计分规则、资源获取、学习过程三个方面描述。\n1. 计分规则 # 计组分为理论、实验两个部分。我们这一届，理论成绩占比 60%，实验成绩占比 40%。实验部分就是令人闻风丧胆的计组上机，理论部分包括期末考试和平时作业两部分，不同老师给分不同。\n计组的老师都非常棒，因此在选课时没有需要避雷的。\n学习过程中，为了效益最大化：\n平时可以听 gxp 老师的课，他差不多会按照上机进度去讲对应的实验部分，而其他老师不会。这点很重要，特别是在 p5 流水线设计部分，有他的引导，学起来会轻松很多。 期末复习建议听 xlm 老师的课，前几节课他的研究生会作为助教来讲复习题，最后一节课 xlm 老师会来讲透题级别的总复习，明确告诉你考什么，重点复习什么，字字千金。 至于实验（上机）部分，需要注意：\npre、p0~p2 打好基础，尽量完成课上课下内容，通过即满分。 p3~p7 课上尽力过题，成绩是按照课上过题数量给分，而不是按照挂的次数扣分的。 课上估计有三次 gap（不通过）的机会。 2. 资源获取 # 学习过程中需要靠自己去寻找资源来辅助完成实验部分。\n最主要参考就是往届学长学姐的代码和说明文档，但请注意不要构成抄袭。\n健康计组忠告第一条： 抵制抄袭代码，拒绝剽窃行为。 2.1 GitHub # GitHub 上有许多往届同学的课设代码，简单搜索 BUAA CO 即可找到一大批。\n完成课程后，也欢迎把自己的代码上传到代码仓库，造福以后的学弟学妹们。但请注意要删除自己的个人信息！！！\n使用 git 在最终 commit 之前一定要检查一遍自己提交的版本有没有泄露个人信息，包括但不限于你的账号密码。 tangsongxiaoba/awesome-buaa-co 是我创建的一个 Awesome 项目，收录了 BUAA CO 的学习资源，包括往届代码、博客教程等，欢迎贡献！\n2.2 往届博客 # 在写代码的时候一般是这样一个流程：\nflowchart LR; subgraph Coding direction LR A[阅读要求] --\u003e B[构思架构] B --\u003e C[参考博客] C --\u003e|还有疑惑| D[参考代码] D --\u003e|验证设计| B D --\u003e E[完成编写] end 往届博客是重要资源，是学长学姐对设计文档的进一步解释与完善。其中的解惑与提示往往可以给你带来很大的启发。\n同时，往届博客还包含同学对上机的经验总结，每周一晚上上机之前看看往届博客对上机题的描述，会觉得有准备很多。\n但同时请注意：不同时期的课程组的要求是不一样的，因此往届博客不一定正确，需要仔细对照计组网站给出的教程予以辨别。比如：\n在我们这一届，一开始要求实现的指令集中包含有符号加法的 add，但是一开始要求其表现与无符号加法的 addu 一样。而往届要求实现的指令集包含的却是 addu，两者在 MIPS-C 中的操作码是完全不一样的。 我们的 p7 与往届相比，增加的外设是不一样的，因此也不能完全采用往届同学的代码。 尽信书，不如无书。 我在学习过程中，主要参考的往届博客有两个：\nFlyingLandlord\u0026rsquo;s Blog：神中神，p7 博客写的比课程组的教程好多了（ roife 的魔法科见闻：讲的也非常清晰到位。 这两个博客同时都总结了大量上机题，非常珍贵。\n我们这一届也涌现出了许多精彩博客，在此先推荐两个我知悉的：\nTrash Bin for Chi：室友的博客，同时包含了他写的数据生成相关的经历。他写的数据生成器\u0026amp;对拍器非常强大，是我们寝室的保命依仗（ Lazyfish \u0026amp; chilly_river：首通全满分的大佬博客，每周写完计组甚至还能在周末抽空飞去各地打 ACM。他的 p7 是我写 p7 时的主要参考，虽然感觉写的不够清晰，但都是极为正确的（在我们这一届）。 2.3 其他资源 # 23 级讨论区精华帖整理（正在进行中） 学院云盘链接：指名为“计算机学院 - 学业支持手册”的北航云盘链接，关注水群信息；其中包含专业各年级课程资料以及其他珍贵资料，非常宝贵。 HDLBits：练习 Verilog 的好网站，可以在这里提高 Verilog 的熟练度。 3. 学习过程 # 不要把计组课下拖到周末再完成，不然你会非常痛苦！！！ 这些过程也可以多多参考往届博客以及 23 级讨论区精华帖整理。\n3.1 pre、p0~p2 部分 # 主要学习 Logisim、Xilinx ISE、MARS 等工具的基本使用，Verilog、MIPS-ASM 的基本语法，有限状态机、硬件描述语言的基本思想。课程组网站的教程非常丰富，照着完成即可。其中我觉得重点要注意的有：\n保持对 Verilog 语言的熟悉，因为 p4~p7 主要是编写 Verilog 代码。Verilog 与一般概念的编程语言不同在于执行方式：\nVerilog 描述并行执行的硬件电路，其信号和模块是并行运作的； 一般编程语言是顺序执行的。 也就是说，Verilog 的一些语句的先后顺序并不是它们的执行顺序：它们是并行执行的。 比如：\nalways @ (posedge clk) begin count \u0026lt;= count + 1; ans \u0026lt;= count; end 这 begin-end 语句块中的两句是同时执行的，也就是说 ans 被更新为 count 的原有值而不是自增后的值。\n区分 Moore 型状态机和 Mealy 型状态机：\nMoore 型状态机的输出变化滞后于状态变化，因为其输出只和状态有关。 Mealy 型状态机的输出可以立即响应输入变化，因为其输出与状态和输入都有关系。 这本质上就是第一点提到的并行性（时序性）。有限状态机的输出是由组合逻辑决定的，因此是实时变化的；而状态是由时序逻辑决定的，所以是按时钟周期逐步更新的。\n对于 Moore 型状态机来说，当在本周期状态即将发生变化时，状态的实际更新会在下一个时钟周期完成。输出逻辑在下一个时钟周期才会检测到状态的变化，并根据组合逻辑更新输出值。\n对于 Mealy 型状态机来说，即使在本周期状态还未完成更新，输出也可以在本周期根据输入的变化立即改变。而状态的更新依然会在下一个时钟周期完成。\n其他部分乏善可陈，基本工具多用用，MIPS、Verilog 代码多写写就熟练了。\n3.2 p3~p7 部分 # p3 是 Logisim 单周期 CPU 的搭建。\n万事开头难，p3 也许是前期比较麻烦的一次任务，需要用图形化的 Logisim 把 CPU 搭建起来。建议善用 Tunnel 部件。\n在开始搭 CPU 之前建议先把数据通路画一遍，理清思路。整个 CPU 的数据通路大致如下：\nflowchart LR; subgraph CPU direction LR; PC --\u003e|pc| IM; PC --\u003e|pc| NPC; IM --\u003e|rs| RF; IM --\u003e|rt| RF; IM --\u003e|rt| mux1; IM --\u003e|rd| mux1; IM --\u003e|imm16| EXT; IM --\u003e|shamt| ALU; IM --\u003e|j26| NPC; mux1 --\u003e RF; RF --\u003e|RD1| ALU; RF --\u003e|RD2| mux2; RF --\u003e|RD2| DM; EXT --\u003e|extImm| mux2; mux2 --\u003e ALU; EXT --\u003e|extImm| NPC; NPC --\u003e|NPC| PC; NPC --\u003e|pc+4| mux3; ALU --\u003e|res| DM; ALU --\u003e|res| mux3; DM --\u003e|RD| mux3; mux3 --\u003e|WD| RF; end 以上并未包含控制器单元到各元件的连线。Mermaid 流程图没法确定位置，看上去不够直观，建议在过程中使用 draw.io 绘制 CPU 数据通路图。\nLogisim 的使用过程本身也就是一个画图的过程，所以其实也可以不绘制这个草稿。不过最终在 Logisim 顶层模块中的 CPU 数据通路应该和以上草稿的层次是一样的。也就是说，各个模块的内部连线应在子模块中完成，不要放到顶层模块中，以免增加模块复杂度导致调试难度的提升。\n在 p3 可以借鉴一部分往届的代码，但不同人的 Logisim 设计很难一样，所以借鉴意义并不是很大；此外不同时期课程要求不同，也会导致与往届同学的 Logisim CPU 对拍失效，所以谨慎参考。\np4 是 Verilog 单周期 CPU 的搭建。\n有了 p3 的基础，p4 只是将图形转化为代码，本质上没有区别。只是要多注意 Verilog 端口接线正确。Verilog 代码复杂冗长，建议配置好编程环境以进行代码检查与风格规范，在编写过程中也要时刻保持清醒，注意接线正确。\n从 p4 开始，往届同学的代码就比较有借鉴价值了，阅读往届代码往往可以加快课下任务的完成。但请确保你一定完全理解了代码及其原理（否则课上就难了），以及再次强调：不要抄袭！\np5 是 Verilog 流水线 CPU 的搭建。\n个人感觉 p5 是压力最大的一次任务，流水线概念理解非常困难，但是搭建时间同样只有一周，往往到课上还不能保证课下设计完全正确，而课上还很难。按顺序要做的有三件事情：\n增加五级流水线寄存器。 增加转发、暂停数据通路。 增加暂停逻辑。 增加转发逻辑。 这里比较难的就是数据通路和暂停转发逻辑。数据通路的问题是：究竟哪些部件要向前转发到哪些部件？ 暂停转发逻辑的问题则是对 AT 法的正确认识。这里个人感觉最麻烦的还是数据通路。建议听 gxp 老师的课以加强理解。\np6 是在 p5 的基础上增加乘除槽、更多指令以及改造 DM。难度也不大，照着教程走就行。\np7 是在 p6 的基础上进一步完善整个 MIPS 微系统，四舍五入就是一个 SoC。 p7 是继 p5 之后更艰巨的一次任务，概念理解更加困难，代码量也更大。而且，其中对于外设的要求每年都有所变化，往届代码的参考价值降低了（但大部分还是可以参考的）。p7 任务主要分为两部分：\n支持异常与中断 添加 Bridge 与外设，形成 MIPS 微系统 最终形成的 Verilog 代码结构如下。\nblock-beta block columns 1 block columns 3 IM int[[\"Interrupt\"]] DM end space:2 block columns 3 Peripherals space Bridge end space block columns 3 Pipeline space CP0 end end IM -- \"instr\" --\u003e Pipeline Pipeline --\u003e IM DM -- \"mem\" --\u003e Bridge Bridge --\u003e DM Bridge --\u003e Peripherals Peripherals --\u003e Bridge Bridge -- \"mem\" --\u003e Pipeline Pipeline --\u003e Bridge Bridge -- \"signal\" --\u003e CP0 int -- \"signal\" --\u003e CP0 Pipeline -- \"Exception\" --\u003e CP0 CP0 --\u003e Pipeline ","date":"15 January 2025","externalUrl":null,"permalink":"/posts/co23summary/","section":"归档","summary":"","title":"BUAA CO 学习心得","type":"posts"},{"content":"","date":"15 January 2025","externalUrl":null,"permalink":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/","section":"标签","summary":"","title":"计算机组成","type":"tags"},{"content":" 最好的计划就是没有计划……\n写在前面 # 不知道第几次建站了，从小学五六年级开始想着要有自己的个人网站，反复折腾，弄好又弃坑……搭建在 Github 上也有好几个版本了。反正重开一次总是要写这些话，希望它能一直开张下去之类的美好祝愿吧（\n暑假刚好只剩下一个月了……前几周忙着社会实践和志愿活动，但这周回到家后好像也无所事事。遂写一份计划，列一下剩下的一个月里要做的事情吧。\n（24 年 11 月 27 日更新）转眼大二上学期也要过去了，这期间我也没有养成写博客的习惯，但确实想到了很多可以记录的事情。但回过头来看这篇文章，暑假计划也变成暑假总结了，而实际上两个月的暑假几乎什么也没有做成……\n暑假计划 # 程设通关指北 # 描述：暑假里打算给下一届的新同学们出一份《程序设计基础》课程的帮助。 缘由：从我们这一届来看，差距真的很大。学了一年，既有码风良好、效率优秀的，也有面向 CSDN 编程的。不多说了，希望能帮到大家吧。 成果：完成的时候这里会放 程设通关指北 (WIP) 的链接。 折腾 NixOS # 描述：系统已经安装好了，暑假里的目标是把系统配置好。 缘由：这是个 OS as Code 的系统，能通过配置文件一键设置好整个系统，想想就觉得很爽，所以一定要折腾一下。 成果：配置文件会上传到 Github，完成的时候这里会放 repo 的链接。 准备数模竞赛 # 描述：准备九/十月份的数学建模比赛，包括学习使用 Matlab 等等（其实我也不知道要学什么）。 缘由：年初过生日的时候被同学拉来要打数模，现在还有一个多月，感觉要寄。 成果：完成的时候放点笔记的链接。 预习大二课程 # 描述：花点时间学学 CO、概统、物理等课。 缘由：害怕回去被卷死。 成果：完成的时候放点笔记的链接。 监督妹妹学习 # 描述：妹妹过完暑假九年级了，暑假还是教教她吧，免得高中也考不上。 缘由：如上。 成果：完成的时候放张她打卡的表格。 折腾个人网站 # 描述：把个人网站上线且配置好。 缘由：因为要出《程设通关指北》啊。 成果：能有这篇文章，说明完成一半了。 其他安排 # 学点吉他 # 等 castle 回来去找他学学吉他。但其实想学 bass。\n写个 SSG # 这几天网站博客配置的头疼，想自己写一个 SSG，最好能够专注于写 Markdown 而只需要极少的配置的，不知道能不能实现。\n学学粤语 # 广东人怎么能不会粤语呢……寒假回访 UM 之前学会讲。\n结尾 # 一口气写完计划看上去还挺充足的，非常符合我天马行空而又不切实际的特质。不知道最后能完成几项啊。“暑假计划”部分截至正式开学的时间。加油吧。\n回顾 # 程设通关指北最后搁置了，创业未半而骈死于槽枥之间。不过后来通过了助教选拔考试，当上了航 C 助教，和这个计划反倒没有什么关系了。 NixOS 最后也删除了，没有继续研究下去。OS as Code 的理念确实好，但是总感觉用不上，导致自己动力不足。事实上，现在的 Windows 10 也准备重装了，也许今后会再次尝试。 数模竞赛在暑假是什么也没有准备，最后上场三天通宵两天把代码搓出来，拿了一个省二，算是意外的收获吧。 大二课程是一点也没有看。CO Pre 教程在暑假返校后做了一点，但开学后又犯了拖延症，一直到 Pre 上机（到现在也）还没完成。 监督妹妹学了两个星期，之后也不了了之。 个人网站在开学后搁置到了现在，为了阿里云备案而重新拾起…… 吉他没学，SSG 没写，粤语也不会。 总的来说就是一事无成，也许有些栏目可以给个半对表示完成了一半，但……没有意义。我马上要存在 20 年了，但对于我自己的认识还颇少，总是不相信自己的无能与怯懦，心里想着宏大的计划，但实际上却像这篇文章一样一事无成。\n","date":"20 July 2024","externalUrl":null,"permalink":"/posts/plan24su/","section":"归档","summary":"","title":"2024 年暑假总结","type":"posts"},{"content":"","date":"20 July 2024","externalUrl":null,"permalink":"/tags/%E5%81%87%E6%9C%9F/","section":"标签","summary":"","title":"假期","type":"tags"},{"content":"","date":"20 July 2024","externalUrl":null,"permalink":"/tags/%E7%94%9F%E6%B4%BB/","section":"标签","summary":"","title":"生活","type":"tags"},{"content":"","date":"20 July 2024","externalUrl":null,"permalink":"/categories/%E9%9A%8F%E7%AC%94/","section":"分类","summary":"","title":"随笔","type":"categories"},{"content":"","externalUrl":"https://blog.cast1e.top/","permalink":"","section":"友链","summary":"","title":"cast1e","type":"friends"},{"content":"","externalUrl":"https://kie-chi.github.io/","permalink":"","section":"友链","summary":"","title":"Chi","type":"friends"},{"content":"","externalUrl":"https://wtxyz.cn/","permalink":"","section":"友链","summary":"","title":"OWPETER","type":"friends"},{"content":" 人生的篇章，在此轻启心扉。 我是北京航空航天大学计算机学院二年级学生。\n","externalUrl":null,"permalink":"/about/","section":"欢迎！","summary":"","title":"你好！","type":"page"},{"content":" 知识的脉络，在此交织成章。\n","externalUrl":null,"permalink":"/categories/","section":"分类","summary":"","title":"分类","type":"categories"},{"content":" 流动的时光，在此留下足迹。\n","externalUrl":null,"permalink":"/moments/","section":"动态","summary":"","title":"动态","type":"moments"},{"content":" 缘分的桥梁，在此连接你我。\n","externalUrl":null,"permalink":"/friends/","section":"友链","summary":"","title":"友链","type":"friends"},{"content":" 时光的碎片，在此安放。\n","externalUrl":null,"permalink":"/posts/","section":"归档","summary":"","title":"归档","type":"posts"},{"content":" 思绪的标签，在此汇聚成海。\n","externalUrl":null,"permalink":"/tags/","section":"标签","summary":"","title":"标签","type":"tags"},{"content":" 万象的缩影，在此徐徐展开。\n这里是 tsxb 的个人博客，我会在这里分享一些自己的生活见闻，技术感悟。\n你可以访问以下页面来获取这个博客包含的更多信息：\n📚 归档：这里按日期排列了我所有的文章。 🗂️ 分类：这里按分类列出了我所有的文章。 🏷️ 标签：这里按标签列出了我所有的文章。 📖 关于：这里是我的个人介绍页面。 🤝 友链：这里是我的朋友们的博客链接。 🌟 动态：这里是我的动态。 ","externalUrl":null,"permalink":"/","section":"欢迎！","summary":"","title":"欢迎！","type":"page"}]